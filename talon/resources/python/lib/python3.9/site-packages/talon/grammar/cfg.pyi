import itertools
import threading
from _typeshed import Incomplete
from talon import events as events
from talon.api import ffi as ffi, ffi_string as ffi_string, lib as lib
from talon.grammar import Grammar as Grammar, optimizer as optimizer
from talon.grammar.dfa import NFA as NFA, WordModel as WordModel
from talon.grammar.dfa_compile import builtin_rules as builtin_rules
from typing import Optional, Sequence, TypeVar

FLAG_NONE: int
FLAG_TERM: int
FLAG_SKIP: int
W2L_RULE_OFFSET: int
TOKEN_LMWORD: int
TOKEN_LMWORD_CTX: int
TOKEN_SKIP: int
cfg_edge16: Incomplete
cfg_struct16: Incomplete
EMPTY_CFG: Incomplete

def dfa_to_cfg(dfa: NFA, tokens: Sequence[str]) -> bytes: ...
def cfg_to_dfa(cfg: bytes, tokens: Sequence[str]) -> NFA: ...
def parse_linked_cfg(cfg: bytes, tokens: Sequence[str]) -> tuple[NFA, dict[str, NFA]]: ...
T = TypeVar('T')

class CacheEntry:
    key: str
    value: T
    serial: int
    def __init__(self, key, value, serial) -> None: ...

class Cache:
    cache: dict[str, CacheEntry[T]]
    hits: int
    misses: int
    evicts: int
    purges: int
    clears: int
    nonce: itertools.count
    lock: threading.Lock
    max_size: int
    list_misses: int
    def __init__(self, max_size: int) -> None: ...
    def get(self, key: str) -> Optional[T]: ...
    def put(self, key: str, value: T) -> None: ...
    def purge(self, key: str) -> None: ...
    def clear(self) -> None: ...
    def print_stats(self) -> None: ...

class CFGEntry:
    blob: bytes
    inlined_lists: set[str]
    def check_lists(self, mutated_lists: set[str]) -> bool: ...
    def __init__(self, blob, inlined_lists) -> None: ...

class ListEntry:
    words: set[str]
    cfg_blob: bytes
    def __bool__(self) -> bool: ...
    def __init__(self, words, cfg_blob) -> None: ...

class CFGLinker:
    word_model: WordModel
    tokens: list[str]
    debug: bool
    lock: threading.Lock
    grammar: Optional[Grammar]
    strtab: bytes
    subrules: list[str]
    subrule_map: dict[str, int]
    linked_l1: Optional[bytes]
    cfg_l1: Optional[CFGEntry]
    cfg_l2: Cache[CFGEntry]
    list_l1: dict[str, ListEntry]
    list_l2: Cache[ListEntry]
    mutated_lists: set[str]
    def __init__(self, tokens: list[str], word_model: WordModel, *, debug: bool = ...) -> None: ...
    def sync_grammar(self, grammar: Grammar): ...
    def compile_grammar(self, grammar: Grammar, subrule_map: dict[str, int]) -> CFGEntry: ...
    def compile_list(self, name: str, words: set[str]) -> bytes: ...
    def link(self) -> bytes: ...
    def match(self, text: str, *, cfg: bytes = ...) -> bool: ...

class CFGEdge:
    token: int
    offset: int
    @classmethod
    def unpack_from(cls, buf: bytes, offset: int) -> CFGEdge: ...
    def __init__(self, token, offset) -> None: ...

class CFGNode:
    flags: int
    edges: list[CFGEdge]
    @classmethod
    def unpack_from(cls, buf: bytes, offset: int) -> CFGNode: ...
    @property
    def terminal(self) -> bool: ...
    def __init__(self, flags, edges) -> None: ...

class CFGCursor:
    addr: int
    idx: int
    stack: list['CFGCursor']
    def advance(self, add: int = ...) -> CFGCursor: ...
    def jmp(self, addr: int, add: int = ...) -> CFGCursor: ...
    def call(self, addr: int, dst: int, add: int = ...) -> CFGCursor: ...
    def ret(self) -> CFGCursor: ...
    def __init__(self, addr, idx, stack) -> None: ...

def cfg_match(full_cfg: bytes, text: str, *, indexed: bool, tokens: list[str], word_model: WordModel) -> bool: ...
